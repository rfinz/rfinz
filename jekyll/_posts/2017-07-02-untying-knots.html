---
layout: post
title: Untying Knots
categories: attempts
---


<div id="outline-container-org653d633" class="outline-2">
<h2 id="org653d633">Untying Knots: Suspicion in the 21st Century</h2>
<div class="outline-text-2" id="text-org653d633">
<blockquote>
<p>
Problems cannot be <br />
Resolved at once. <br />
Slowly untie knots <br />
Divide to conquer.
</p>

<p>
&#x2013; Deng Ming-Dao
</p>
</blockquote>

<p>
When parsing the sometimes erudite musings of the meta-rational
internet, you must give the gamut of ideas cool consideration,
weighing post-modern, modern, and medieval alike; refusing to give in
to the demands of systems that are too quick to declare truth, too
fixed in their understanding, and, from these initial shortcomings,
too unwilling to engage in solutions. From the flexibility in its own
ideology stems a general unease with the state of things&#x2013; the
unwillingness to talk, the obstructionism, the <i>ad hominem</i> nature of
nearly all argument at the national level, the constant poisoning of
the well, and the tendency of the internet to amplify these features
as commentators sit miles away, safe behind their computer screens,
with virtually no chance of consequences for behavior that would be
absolutely abhorrent if executed in the IRL. Couple this with an
intellectual milieu that is both combative and elitist, and it's clear
that the global conversation leaves much to be desired. What's the
problem?
</p>

<p>
In recent months, it appears to me that the internet's brightest
thinkers have been circling the drain, attempting to converge on a
common enemy. It also seems to me that they've come to an informal
conclusion: the enemy in academia is <i>critique's</i> election to its
current status as knowledge's best excavator &#x2013; privileged among tools
to unearth true meaning, shatter the facade of previous knowledges,
and expose artifice.
</p>

<p>
From Heather MacDonald in the Spring 2017 issue of <a href="https://www.city-journal.org/html/true-purpose-university-15134.html">City Journal,</a> to
Fuck Thought's <a href="https://www.artforum.com/slant/id=65193">Syllabus for the End of Times</a>, to the endless critique
of critique I see in the wild, it's become clear that if we go for a
dive in the tepid water that is drowning modern academia, we'll find
wads of lackluster critical practices stuffed&#x2013;enthusiastically&#x2013;into
the drain. It seems inescapable. Rita Felski hit the nail on the head
in her 2012 essay "Critique and the Hermeneutics of Suspicion":
</p>

<blockquote>
<p>
Critique is contagious and charismatic, drawing everything
around it into its field of force, marking the boundaries of what
counts as serious thought. For many scholars in the humanities, it is
not just one good thing but the only conceivable thing. Who would want
to be associated with the bad smell of the uncritical?
</p>

<p>
&#x2013; <a href="http://www.journal.media-culture.org.au/index.php/mcjournal/article/view/431">Rita Felski</a>
</p>
</blockquote>

<p>
To be uncritical is to be unthinking, and the unthinking is the stooge
of social consensus. Critique is <i>how we get better</i>, so we better
keep doing it.
</p>

<p>
It's more than that. As Hanzi Freinacht has <a href="http://metamoderna.org/4-things-that-make-the-alt-right-postmodern?lang=en">noted</a>, the reflex to
critique, through critique's own negative affect, becomes a reflex to
dismiss: "a proposal dismissed is a job well done," and this reflex to
dismiss is pan-political and self-escalating. A strong critical
reading looks and feels like paranoia: it looks to root out what has
not been said, who was implicitly or tacitly targeted or erased by the
work, and who any co-conspirators might be. Who benefits? Who profits?
Why are they doing this? Maybe the reason is the establishment of a
New World Order, or maybe it's the buttressing of the Old. Maybe the
dichotomy between the two must be examined critically for better
understanding. Whatever way, critical contextual analysis is the name
of the game.
</p>

<p>
Things dismissed tend to dismiss in turn. Urbanites dismiss country
folk as bumpkins and those same bumpkins will not hesitate to dismiss
urbanites as city-slickers. In rural senate races representatives are
raked over the coals for spending too much time in the city. Anyone so
comfortable with the concrete and at ease with the constant noise of
the city must have an agenda that dismisses country-folk and belittles
their needs, common rhetoric would indicate.
</p>

<p>
Eventually dismissal out of hand becomes a relegation to taboo, and
soon those ideas gain a certain dark psychic power, a counter-cultural
veneer.
</p>

<p>
Who can say whether short-circuiting an idea with taboo or allowing it
to vanish (through audience) into banality is more effective? There
are probably other options. Who knows? With few sociological tools
equipped to handle such inquisitions, the temptation always remains to
critique and dismiss, taboo and censor.
</p>

<p>
So here I will attempt to array the constituent parts of critique with
some accuracy, make merry in the mechanisms themselves, and slide like
oil between the gears, happy for the tooth-edged gap in which I
play. The joy of the meta-critical.
</p>
</div>

<div id="outline-container-org940811b" class="outline-3">
<h3 id="org940811b">Postmodernism and the privileging of the paranoid process</h3>
<div class="outline-text-3" id="text-org940811b">
<p>
At some point postmodernity gave up. Critiquing the fundamental logic
that underpinned the world's meta-narratives gave way to critiques of
the logic of the <i>dominant</i> meta-narratives, with diminishing
recognition that we have little reason to assume that <i>any</i> narrative
is more correct than the next. The postmodern got a little less crazy
in its eternal september. A certain moral contamination began to work
against the deconstructive impulse, rendering deconstruction itself
nearly unable to introspect.
</p>

<p>
Under these new rules, instead of attempting to understand <i>what</i> has
been said, drawing from spatio-temporal clues to create dialogue
between texts and situate words in the historical conversation, we
must instead use those same clues to determine <i>why</i> something is
being said, with a suspicious eye turned towards the biases and
<i>regimes of truth</i> that fascistically ensnare the modern thinker. In
this new regime <i>con</i>text finds itself
transformed into <i>sub</i>text, a new, fertile
ground for paranoia.
</p>

<p>
These contemporary readings, in their search to justify their
paranoia, read implicit bias unless explicitly noted, and throw into
question the validity of modern ways of knowing, <a href="http://onlinelibrary.wiley.com/doi/10.1111/j.1741-6787.2006.00058.x/full">occasionally</a>
including the thoroughly vanilla epistemologies of modern
post-positivism (the <i>tl;dr</i> of post-positivism being that scientific
truths are statistical and conjectural in nature, and that human
biases pollute the search for truth). This even exactly the point. The
more vanilla and everyday our knowledge seems, the more likely it is
to be polluted, these methods proclaim.
</p>

<p>
With no hold on the truth, and the pure, fertile land of paranoia
stretching out to the edges of our vision, it now, in a deconstruct-y
ouvre-of-the-modern-times critique-y sort of way, seems our
hegemonically imposed duty to find the fault in whatever we are doing
and throw the grain of truth away with the bath water. Or something
like that. Read this:
</p>

<blockquote>
<p>
The man of suspicion double-bluffing the man of guile: in the hands of
thinkers after Freud, paranoia has by now candidly become less a
diagnosis than a prescription. In a world where no one need be
delusional to find evidence of systemic oppression, to theorize out of
anything but a paranoid critical stance has come to seem naive, pious,
or complaisant.
</p>

<p>
&#x2013;Eve Kosofsky Sedgwick, <i>Paranoid Reading, Reparative Reading</i>
</p>
</blockquote>

<p>
Written in 2003, Sedgwick's work seems prescient in a world that now
seems absolutely overrun by the critical. Not even the critical, the
<i>pop</i>-critical. Even the un-paranoid that lay mercifully outside of
the academy now seem naive and ignorant. Paranoia escaped academia and
infected the masses. Maybe.
</p>

<p>
Unfortunately, this isn't where paranoia's reach ends. Paranoia
continues to be self-propagating, a property of the affect that is
also explored in detail by Sedgwick.
</p>

<blockquote>
<p>
[P]aranoia tends to be contagious; more specifically, paranoia is drawn
toward and tends to construct symmetrical relations, in particular,
symmetrical epistemologies.
</p>

<p>
&#x2013;Eve Kosofsky Sedgwick, <i>Paranoid Reading, Reparative Reading</i>
</p>
</blockquote>

<p>
The brutal truth that paranoia is only truly understood by being
paranoid, a process that, once engaged, limits recourse for its object
such that there's very little option but for it to conduct itself in a
paranoid manner as well.
</p>

<p>
I don't even disagree(do even agree?) with the prescription of greater
imagination and new ways of thinking that much of post-modernism
revolves around. And that's the point. It's the suspicious modes and
mimetic mechanisms of paranoia that are not well suited for a world
where every idiot with a computer can type words and transmit
half-formed ideas at the speed of light. We need ways of thinking that
can deal effectively with the information firehose, and unfortunately
postmodern critical methods don't seem up to the task.
</p>
</div>
</div>



<div id="outline-container-org77c3c18" class="outline-3">
<h3 id="org77c3c18">Fascism and politics empowered by paranoia</h3>
<div class="outline-text-3" id="text-org77c3c18">
<p>
We can hardly get through a sentence of an opposing partisan's view
without identifying them as a bad actor. With any inspection at all it
seems as though our governors are engaged in myriad conspiracies to
maintain the global oligarchy and undermine the working people. How
you imagine that's being done, and which oligarchs you think are being
aided, is probably what defines your politic.
</p>

<p>
With that, do our political (narrative?) preferences manifest
themselves as tribes of paranoia(the other way aroud?)? Is it the
stories we tell ourselves about causality and the direction present
therein that define our fears, worries, and preferences? Are the
mimetic forces of paranoia what drive our <a href="http://slatestarcodex.com/2014/09/30/i-can-tolerate-anything-except-the-outgroup/">insane</a> in-group preferences
and out-group banishment?
</p>

<p>
Given how strong the forces are that deem to divide us, it seems
unlikely that the explanation is mere serendipity. It even,
increasingly, seems unlikely that divisions are drawn up along the
borders of race, religion, or language. From my vantage point it looks
most likely that tribal lines are drawn along the lines of shared
suspicion&#x2013; now empowered by narrative and promulgated by academically
mandated critique.
</p>
</div>
</div>

<div id="outline-container-orgd9a2a97" class="outline-3">
<h3 id="orgd9a2a97">Journalism, Punditry, Blog Post, Narrative</h3>
<div class="outline-text-3" id="text-orgd9a2a97">
<p>
There is an intelligensial subculture, born from new paths to fame and
notoriety, justified through calls to the truth, financed by
persuasion made monetary, and tasked with creating narrative from mere
fact. Situated in this, pundits are a particular type of commentator whose sole
job it is to find speculation, take it for a swim with what they "know",
and spit it back out. Journalists and bloggers may not accept the
pundit identity, but will engage in punditry nonetheless.
</p>

<p>
Professionals like these have become adept at simultaneously thinking
paranoiacally and fitting facts into ideology &#x2013; explicitly at a 12th
grade reading level. Their status as both accessible and "correct" has
sequestered them in a class of their own. The paranoid
class. Purveyors of narrative. Unwitting(or witting) shapers of
reality.
</p>

<p>
This class writes (or speaks) a lot. It's their job. The more opinions
that they can get out of their head and into the air the better. I bet
you could correlate global warming and pundit word counts.
</p>

<p>
To willing subjects consuming punditry or journalism (perhaps what
they're reading signaled all of the right values before they've even
begun), the sparse nature of text allows the reader to project
themselves into the gaps, taking only emotional cues, leaving only
agreement. To unwilling readers, the gaps in the text seem to be
filled <i>with the writer</i>, allowing paranoid interpretive reflexes to
kick in, and dispelling all possibility of consensus.
</p>

<p>
It's in this space that the paranoid class can breed. Bloggers about
bloggers and journalists about journalists and pundits about pundits
have found their home criticizing their tribal counterparts. Narrative
can always be news, and news is always narrative.
</p>

<p>
In most professions, journeymen(journeypersons?) are expected to be
the keepers of craft, for they alone possess the profound
understanding it takes to be an effective practicioner of their
trade. They might inhabit a feeling for the material&#x2013;the mechanic's
touch&#x2013;or a respect for time-honored processes; either of which are
hard-won by years of practice, inquiry, defeat, and
persistence. Journeypersons have honed their tools, and dug well below
the surface to discover the parts of <a href="{% post_url 2017-04-19-chunks %}">chunks</a> that thinkers and
journeymen before them buried there long ago.
</p>

<p>
As far as journalists, pundits, bloggers, and other storytellers are
concerned, their medium, their material, their massage <i>is</i> the
narrative. The fibers that they bend are the fibers of reality, and
the tapestry that they weave must be consistent, the rows of fiber
even and orderly, the story <i>compelling</i>.
</p>

<p>
Even as the paranoid hone their craft and become more and more
convincing, the pressure to publish quickly limits the quality of the
exploration, which in turn makes even the (supposed) inherent power of
the narrative shallow and uninteresting.
</p>

<blockquote>
<p>
[O]ne understands paranoia only by oneself practicing paranoid
knowing, and &#x2026; the way paranoia has of understanding anything is by
imitating and embodying it.
</p>

<p>
&#x2013; Eve Kosofsky Sedgwick, <i>Paranoid Reading, Reparative Reading</i>
</p>
</blockquote>

<p>
Just like paranoia, narrative compels narrativization in order to be
understood. Stories are best understood in terms of other
stories. Archetypes and tropes are the language of understanding in
this domain. Of course, since narrative is not an affect(??) I cannot
say that it "tries to understand" anything, except in the most trivial
sense.
</p>

<p>
This makes intuitive sense, though. Like their predecessors,
historians, poets, and other tellers of tales, the new journo caste
has only one job: post-hoc narrativization of otherwise disparate
events.
</p>

<p>
A journeyperson of the narrative art does not, necessarily, understand
the true, deep reality of whatever it is that they write about, since
they are mathematically unable to spend as much time in any situation
as their subjects&#x2013;instead they possess greater and greater
understanding of what makes narrative compelling. What <i>forces</i> a
reader to engage and sympathize, to build connections and trust. The
journalist's instinct to distill and simplify is predominantly good
for two things&#x2013; instilling the illusion of understanding in
laypeople, and insuring that they trust that understanding.
</p>
</div>
</div>

<div id="outline-container-org9a126d6" class="outline-3">
<h3 id="org9a126d6">Following the golden thread</h3>
<div class="outline-text-3" id="text-org9a126d6">
<p>
Occasionally I've felt as though my life has had a guiding force, a
golden thread that I could pick up and follow, a pulsating golden
light laid out before me as if guiding me towards my next objective in
some sort of reality based video game.
</p>

<p>
This, probably, is hypomania. Or maybe it's a flow-state. Or maybe
it's just the <a href="https://en.wikipedia.org/wiki/Illusion_of_control">illusion of control</a> creeping in. Control: that necessary
human illusion that imbues us with purpose and staves off
hopelessness.
</p>

<p>
The string metaphor for purpose and control crops up
elsewhere. Businesses or organizations that seem to <i>miss the mark</i>
(as if there were a target) can also be said to have <i>lost the
thread</i>, as though there is only one correct path through the
labyrinth, out of the cave, and back into the light.
</p>

<p>
Even in my day to day, though not imbued with the same inspiring
light, there is a sense that I am following a thread from place to
place. The interplay of consciousness and time coalesce into this
illusion&#x2013; a string of sense and meaning connecting events.
</p>

<p>
The trick, of course, is that sometimes we're following the thread and
sometimes we're laying the thread down behind us. Some of our
faculties work more like reflexes than consciousness, and the
interplay of those with the outside world can sometimes not be
avoided. Sometimes the world is configured with such weight that our
own inputs can contribute very little. But sometimes we can make an
effect. Sometimes our input is meaningful. Sometimes we possess actual
control.
</p>

<p>
Understanding those moments <i>in situ</i> is difficult, but
important. Using these control moments wisely is how we make personal
progress, and mis-categorizing these moments is one of our greatest
sources of personal fallacy. The difference between reality and
narcissism is in our <a href="https://en.wikipedia.org/wiki/Locus_of_control">Locus of Control</a>, the difference between reality
and conspiracy located somewhere near the <a href="https://en.wikipedia.org/wiki/Fundamental_attribution_error">Fundamental Attribution
Error</a>.
</p>
</div>
</div>

<div id="outline-container-orgfe70353" class="outline-3">
<h3 id="orgfe70353">Narrative Reward / Conjunctive Maths</h3>
<div class="outline-text-3" id="text-orgfe70353">
<p>
Narrative <i>feels</i> good. The right narremes in the right places tickle
our intuition and inspire sympathetic responses in our brain and
body. We are <i>transported</i> into the head space of the characters,
where our overactive empathy works to make sure that our emotions
reflect theirs exactly.
</p>

<p>
I think (and many others think at this distinct juncture in time) that
narrative feels <i>so</i> good that we tend to view everything in terms of
narrative, even if the evidence is sparse that such causal
explanations are factual. Especially as our access to stories begins
to border on unlimited, and our forays into the neuroscience of
storytelling push us towards a <a href="http://greatergood.berkeley.edu/article/item/how_stories_change_brain">perfected</a> affectual control, we will
become more susceptible to this failure.
</p>

<blockquote>
<p>
The narrative fallacy addresses our limited ability to look at
sequences of facts without weaving an explanation into them, or,
equivalently, forcing a logical link, an arrow of relationship upon
them. Explanations bind facts together. They make them all the more
easily remembered; they help them make more sense. Where this
propensity can go wrong is when it increases our impression of
understanding.
</p>

<p>
&#x2013; Nassim Nicholas Taleb, <i>The Black Swan</i>
</p>
</blockquote>

<p>
It's a hard problem to have. Even adding details to "flesh out" a
narrative does nothing for its validity. Details interpolated,
extrapolated, any detail except those actually recorded from reality
(a difficult thing to do, indeed), actually reduce a narrative's
chance at reflecting reality.
</p>

<p>
This isn't some rhetorical slight of hand. This is a mathematical
truth of the universe: as you add conditions that a model, a
narrative, or a story <i>must</i> obey, it becomes vanishingly likely. Is
it more likely that a given terrorist is a conservative? Or a
conservative with mental health issues and a gun? What about an
Islamist? What about an Islamist with mental health issues and a bomb?
Think about it for more than a second and you'll quickly come to
understand how deficient narrative, <i>any narrative</i>, is as a
predictive model.
</p>

<p>
That is, of course, not to say that there aren't constructed
narratives out there that are mostly correct&#x2013; there
are. Unfortunately, even post-hoc analysis of the events has a hard
time determining what past correctness means when attempting to
predict future events. Human beings are liable to assign causality
when in fact there is only chance, and recommend chance when the
mechanisms seem too obscure or complex to comprehend. Single, one-off
events end up <i>meaning</i> everything, while the predictive realm of
symbols and certainty breaks down when it encounters something new.
</p>
</div>
</div>

<div id="outline-container-org90ac6dd" class="outline-3">
<h3 id="org90ac6dd">Narrative as abstraction / model</h3>
<div class="outline-text-3" id="text-org90ac6dd">
<p>
At the heart of it, storytelling is an essentialization of events. It
is a paring back of the human experience to its most salient
components: for every detail included we must leave out infinitely
more.
</p>

<p>
Reality, by contrast, tends to fractal off into the distance:
processes within processes, coves within coves, an infinite shoreline
if measured with enough detail. The statistical tricks that make our
consciousness work paper over some of that detail, failing to account
for abnormal variations, one off events, and unexpected
synchronicities.
</p>

<p>
The fundamental purpose of abstraction is to reduce complexity. To
pre-brain reality. To do some braining for us. Using chunks that
capture more area but with fewer details in a way that reduces the
barrier to entry for ideas. We "black box" components, machines,
processes, and other complex mechanisms, in order that we may use them
for their explicit inputs and outputs without thinking about their
inner workings.
</p>

<p>
In this same way we can view graphs, pictures, and other graphics as
purposeful simplifications. They contain a programmed output (trend
line, circle size, arrow direction) that represents a thought process
working on a programmed input (variables chosen, data gathered,
processes designed). The image becomes a model of reality, complexity
abstracted away, what's left now simple and workable enough for higher
level enjoyment.
</p>

<p>
What do they say, a picture is worth a thousand words? In these words
I've got four charts worth of abstraction alone. Words are
abstractions too. Whatever we, as authors choose to write, there are
uncountably many more words that haven't been written about the same
subject. The choice of words is statistically a matter of exclusion,
not inclusion. Words become models for concepts and stories become a
sort of meta-model, over-arching concept, order of display.
</p>

<p>
The narratives that we write become black box operators for
classifying future events. Events (inputs) are inserted into the
narrative, and out the other side come interpretations of those
events. With some preparation the inner workings of narratives can now
be forgotten to reduce cognitive load.
</p>

<blockquote>
<p>
The so-called "scientific view of the world" based on this can hardly
be anything more than a psychologically biased partial view which
misses out [on] all those by no means unimportant aspects that cannot
be grasped statistically.
</p>

<p>
&#x2013; C. G. Jung, <i>Synchronicity: An Acausal Connecting Principle</i>
</p>
</blockquote>

<p>
Similarly, reality can be measured however you'd like. Correlations
can be found wherever you look, and coincidence is not far behind.
</p>

<p>
A single human being's conception of the world, this accidental
narrativization, is as one giant Texas Sharpshooter fallacy. The
bullets fired, the barn hit, and nothing yet left but to draw a
target. As Nicholas Taleb and other financiers are wont to say, you
have to be drunk or blind not to find a pattern in randomness.
</p>

<p>
Donald Hoffman has been making the rounds, claiming to know that
reality is nothing close to how we perceive it. I don't know that this
is quite right. I think a more compelling case can be made that
reality is nothing close to how we <i>interpret</i> it. Maybe this is just
sophistry, but it's worth the typing.
</p>

<p>
In one of his talks, Donald Hoffman knowingly <a href="https://youtu.be/6eWG7x_6Y5U?t=9m28s">flashes</a> us a picture of
some beetles swarming a bottle, confused by its shiny, dimpled brown
surface, and believing that the bottle is an incredibly large, fit
mate. Donald quips that we humans have somewhat more discerning taste
in women, that at least we wouldn't be duped by such a simple ruse.
</p>

<p>
We don't swarm bottles accidentally, but aren't we turned on by
animated depictions of anatomy? It's clear that a two-dimensional
representation of sex characteristics can send our mating instinct
into a frenzy. It's clear that what we're not so much attracted to
viable mates, but to the characteristics that <i>signify</i> viable
mates; the <i>symbols</i> that cause us to load our mating chunk.
</p>

<p>
Is video, from a complexity standpoint, so much more different than a
bottle that we can claim to be immune to such tricks? Doesn't makeup
fool one's brain into believing that certain sex characteristics are
present when they are not? I even bet we'll find sex robots (or
virtual reality sex as in the just-alright movie The Zero Theorem)
more universally satisfying in the future, as their symbology moves
out of the uncanny valley.
</p>

<p>
Human beings are aware, <i>consciously</i>, that these things are
facsimile, but <i>subconsciously</i> fall for the same tricks. Can we say
that it is our perception that is broken? Doesn't perception happen in
the conscious realm? What about our subconscious taints our
interpretation such that it's clear we interpret exactly nothing about
the world entirely correctly? If hermeneutics and criticism are
attempts at moving our interpretive mechanisms into the <i>conscious</i>
realm, how can we make sure we do so effectively? How do we avoid the
attribution errors and other biases that taint so much?
</p>

<p>
If it's our interpretation, our analysis, our <i>narrative</i> that's
broken, inherently, <i>evolutionarily</i>, then we must be ever more
vigilant against the creep of grand narratives that might sweep us up
and into fervor. It's not the dimples that deceive us, and it's not
the shiny brown, but all of life is its signifiers, fit into our
narrative &#x2013; our understanding of the way things are.
</p>
</div>
</div>

<div id="outline-container-org2f011cb" class="outline-3">
<h3 id="org2f011cb">P-hacking</h3>
<div class="outline-text-3" id="text-org2f011cb">
<p>
In light of this, I can't be convinced that all scientists that
"P-hack" understand that they are doing something wrong. They're only
messing with the fundamental constituent parts of reality,
anyhow. They're only tripping face first into the gaping chasm that
lies between perception and interpretation.
</p>

<p>
The reality is that if you ask enough questions and gather enough data
you <a href="https://fivethirtyeight.com/features/science-isnt-broken">will</a> be able to find a pattern. You <i>will</i> be able to draw your
target and announce your conclusion.
</p>

<p>
Good science(confirmatory and disconfirmatory science) can only be
done when the target is drawn before the data is collected. It would
be better to regard studies with many measurements as reality surveys,
and analyze them with the eye of the financier, because if a narrative
is given the data reality will have no choice but to conform.
</p>

<p>
Of course, drawing a target is a matter of philosophy ("what does a
measurement <i>mean</i>?"), so confusion is understandable. Maybe this just
means that we should tinker and refuse to worry about it. I don't
know.
</p>

<p>
Statistics are counter-intuitive enough that they can beguile even the
educated, and they frequently allow bias to fester.
</p>
</div>
</div>

<div id="outline-container-orgab084e0" class="outline-3">
<h3 id="orgab084e0">Paranoia as defense</h3>
<div class="outline-text-3" id="text-orgab084e0">
<p>
A cruel world demands justification. "Senseless" world explanations
are inherently unsatisfying. The paranoid reading of reality, one rife
with grand intentions and even grander conspiracies, appeals to the
sensual nature of existence.
</p>

<blockquote>
<p>
We spend our entire lives trying to tell stories about ourselves&#x2013;
they're the essence of memory. They're how we make living in this
unfeeling accidental universe tolerable. That we call such a tendency
"the narrative fallacy" doesn't mean it doesn't also touch upon some
aspect of the truth.
</p>

<p>
Some stories simply literalize their metaphors a bit more explicitly.
</p>

<p>
&#x2013;Ken Liu, Preface to <i>The Paper Menagerie</i>
</p>
</blockquote>

<p>
Paranoia, as Eve Sedgwick says, is the most ascetic form of love. It
demands little from its object, but grants it much attention and
affection.
</p>

<blockquote>
<p>
The first imperative of paranoia is There must be no bad surprises,
and indeed, the aversion to surprise seems to be what cements the
intimacy between paranoia and knowledge per se, including both
epistemophilia and skepticism.
&#x2026;
No time could be too early for one's having-already-known, for its
having-already-been-inevitable, that something bad would happen. And
no loss could be too far in the future to need to be preemptively
discounted.
</p>

<p>
&#x2013; Eve Kosofsky Sedgwick, <i>Paranoid Reading, Reparative Reading</i>
</p>
</blockquote>

<p>
Eliminating surprises works well when you have a relatively finite
number of worries.
</p>

<p>
My intuition is that such paranoia in the modern world is
self-defeating. It pays to fear and to protect yourself from wild
animals or other small tribes. Not so much from giant governmental
mechanisms that can kill or silence you in a thousand ways. Not so
much from the perceived threat of 8 billions of other humans connected
to each other via the series of wires and tubes we call the internet.
</p>

<p>
So please, by all means, fantasize about conspiracies for fun. Love
the drama of life a little bit. But understand that putting money or
effort into such things is gambling &#x2013; playing a lottery you're
unlikely to win.
</p>
</div>
</div>

<div id="outline-container-orgca86857" class="outline-3">
<h3 id="orgca86857">Paranoia without identity groups?</h3>
<div class="outline-text-3" id="text-orgca86857">
<p>
I don't know who you direct your paranoia at if you don't have a sense
of tribal identity. Our collective identities serve as the objects in
our narratives, the agents and injured parties, all. I don't know how
you have tribal identity without paranoia.
</p>

<p>
I also don't know if paranoia exists without tribal identity. Who do
you fear? What must you uncover?
</p>

<p>
How do we decide what parties to trust? Not in a an "honesty" sort of
way, because we can still ultimately trust many of those that are
dishonest to us, but existentially. What other agents do we put our
trust <i>in</i> without the aid of identity?
</p>

<p>
Even the simple matters of context and subtext are rooted in
identity. How do we <i>even understand other people</i> if we don't have
groups to fit them into?
</p>
</div>
</div>

<div id="outline-container-org87bb8ea" class="outline-3">
<h3 id="org87bb8ea">Reparative Methods</h3>
<div class="outline-text-3" id="text-org87bb8ea">
<p>
I don't like to be prescriptive. I don't think that there's any one
thing or few things that can be done to fix the state of
discourse. Still, I'd like to offer suggestions from my own brain. A
few of my own interpretive tools for building understanding from
diverse source materials, including materials from those people that
you would generally be disinclined to believe. It's tricky.
</p>

<blockquote>
<p>
The vocabulary for articulating any reader's reparative motive toward
a text or a culture has long been so sappy, aestheticizing, defensive,
anti-intellectual, or reactionary that it's no wonder few critics are
willing to describe their acquaintance with such motives.
</p>

<p>
&#x2013; Eve Kosofsky Sedgwick, <i>Paranoid Reading, Reparative Reading</i>
</p>
</blockquote>

<p>
The simplest technique is to simply ignore the bad bits of academic
text. Most people ignore irrelevant words almost constantly, and
extending the favor to our philosophical enemies is the least we can
do. Ignoring items you disagree with opens you up to the possibility
of finding some text that speaks to you, and allows you to focus on
the ways that you are alike, rather than different.
</p>

<p>
This is your least effort option, but it's not practical for many
situations. Mostly our differences are important and must be
addressed.
</p>

<p>
The next step, then, is to engage in dialectic. The assumption that
discussion carries mutual benefit is foundational to many reparative
methodologies (family counseling, anarchist micro-government, etc),
and is easily applied to our reading habits. Dialectic moves shared
reality, debate encourages us to pit ideologies in some sort of
winner-takes-all gladiator battle. Is ideology a slave in this
metaphor? Couldn't tell you.
</p>

<p>
Regardless of our adoption of ideas from any person or text that we
engage in dialectic, we can learn something nonetheless. We can learn
the <i>what's</i> and <i>why's</i> of other ideologies. We can understand the
possible of other internally consistent narratives. Maybe by
understanding the fractures and breakdowns of other ideologies we can
more accurately pinpoint the fractures and breakdowns of our own&#x2013;
places where we can ultimately choose to employ other systems of
thinking that are more situationally effective.
</p>

<p>
These unintended consequences are the <i>side effects</i> of ideas. Just
like in medicine (a purely Talebian example), in philosophy progress
in made most often by tinkering and finding the unexpected. Like
Viagra (invented for cardiological disorders), the side effects of
ideas we invent or encounter may be the primary effects we seek in
another domain.
</p>

<p>
Even acting's time-tested method for keeping a scene going, the
classic "yes, and?" allows for more ideas rather than fewer, and could
be considered a reparative technology. I don't know.
</p>

<p>
How often do you read something interesting and then go searching
around for the political leaning of the author before deciding whether
the text should be taken seriously? Is it worth it? What signals have
to be present before you'll trust something?
</p>

<p>
Sometimes I think the real alternative to narrative is to communicate
entirely through the visceral emotional impressions of non-verbal
sound and aesthetic imagery in the way that Andrei Tarkovsky
mastered. Sounds cool at least.
</p>
</div>
</div>
</div>
